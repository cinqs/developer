{"nbformat_minor":5,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","file_extension":".py","version":"3.10.5"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"}},"cells":[{"metadata":{},"execution_count":null,"source":"## 基于 *CNN* 的 *AI* 分类模型开发","id":"080f681e-8c21-4950-9333-a587faa83067","cell_type":"markdown"},{"metadata":{},"execution_count":null,"source":"本案例主要介绍如何快速利用 *AIE Python SDK* 创建机器学习建模流程。我们主要使用到 *Python SDK的Machine Learning Proxy* 模块（下文简称 *AieMlProxy* ）。该模块涵盖了一系列用户与训练集群之间的交互接口，包括：鉴权、数据加载、训练任务提交、任务状态和日志查看、模型推理等。","id":"a077ceb0-51c9-4426-98bb-374f43d95ba2","cell_type":"markdown"},{"metadata":{"tags":[]},"execution_count":null,"source":"### 导入 *AIE Python SDK* 包并初始化","id":"9ad58a0b-325b-45b9-8482-452266b492c7","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"import aie\n\naie.Authenticate()\naie.Initialize()","id":"aaa2b65a-dbd0-4bdd-9464-02c2108112b5","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 创建工作目录","id":"ae78e7b8-9531-41c1-ba2b-101ec1d4e5db","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"PACKAGE_PATH = \"cnn_clf_demo\"\n\n!ls -l\n!mkdir {PACKAGE_PATH}\n!mkdir {PACKAGE_PATH}/data\n!touch {PACKAGE_PATH}/__init__.py\n!ls -l {PACKAGE_PATH}","id":"eab7a704-9d5f-473c-926c-abb0f7d72ec1","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 数据集加载\n\n*AI Earth* 平台目前主要存储和管理三类数据，分别是\n- 影像类（即栅格数据，包括 *Image* 和 *ImageCollection）*\n- 矢量类（包括 *Feature* 和 *FeatureCollection* ）\n- 数据集（除影像、矢量之外的非时空类数据，包括用户上传、代码生成的 *csv、txt、json、zip* 等格式的文件）\n\n其中，数据集 又分为公开数据集和私有数据集。公开数据集采用 *SpatioTemporal Asset Catalog*  ( *<a href=\"https://stacspec.org\" target=\"_blank\">STAC</a>* )进行管理，数据集合或单项数据均有各自全局唯一的 *STAC ID* ；私有数据集为用户自行上传的数据集。","id":"8ad9bbe0-232a-46aa-8ad4-e031ea6d18dd","cell_type":"markdown"},{"metadata":{},"execution_count":null,"source":"#### 公开数据集\n公开数据集包含 *CV* 和遥感领域常见的 *benchmark* ，通过 *MlProxy* 模块提供的 *STAC* 接口来查询和获取。","id":"5b6ff615-03da-46e3-85c8-57089a3eb588","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 导入AieMlProxy模块\nfrom aie.client.mlproxy import MlProxy","id":"6952706b-ab19-4bf6-8ea1-f95feef7201e","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 列出所有公开数据集\nMlProxy.list_stac_datasets()","id":"67fb4314-d791-4baa-bf0b-5aea3581c617","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 通过dataset id获取数据集描述信息，以CIFAR-10数据集为例\nstac_desc = MlProxy.get_stac_dataset(\"AIE_PUBLIC_DATA_CIFAR10_DATASET_V10_20220627\")\nprint(stac_desc)","id":"de0b705f-a6e0-4ce6-aa0d-7f0f08cedfb0","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"\n# 获取数据集split\nTRAIN_PATH = stac_desc.get('train_path')\nVALID_PATH = stac_desc.get('valid_path')\n\nprint(VALID_PATH)\nprint(TRAIN_PATH)","id":"8d8215d3-df39-4ec9-8436-7aa9939eb810","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 私有数据集\n在本项目页面左侧，依次点击 __数据__ → __项目数据__ → __导入数据__ → __自主上传数据__ 以导入特定的单景影像到项目中。\n私有数据集导入以后，默认会挂载到 */home/data* 目录中（可使用终端命令行查看）\n\n<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01RHYAr42AKKBPkQO9l_!!6000000008184-0-tps-1748-872.jpg\" alt=\"drawing\" width=\"1000\"/>","id":"7f8df925-e591-441f-a2b5-220dc7a0321e","cell_type":"markdown"},{"metadata":{},"execution_count":null,"source":"### 配置文件","id":"b0767290-7690-428e-ae6c-ffa3ce547687","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"%%writefile {PACKAGE_PATH}/config.py\n\nOSS_HOST = \"oss-cn-hangzhou-internal.aliyuncs.com\"\nOSS_WORK_DIR = \"pai/cnn_clf_demo\"\nOSS_CHECKPOINT_DIR = \"pai/cnn_clf_demo/checkpoint\"\n\nOPEN_DATA_BUCKET = \"aie-sample-data\"\nOPEN_DATA_ENDPOINT = \"http://oss-cn-hangzhou-internal.aliyuncs.com\"\n\n# Ouput info\nOUTPUT_MODEL_FILE_NAME = \"cnnDemoModelBest.pth\"\n\n# Local tmp dir on PAI Cluster (to save dataset)\nPAI_LOCAL_TMP_DIR = \"./tmp/\"\n\n# Hyperparams\nBATCH_SIZE = 256\nNUM_LABELS = 10\nNUM_EPOCHES = 1\n\n\nSTAC_TEST_PATH = \"\"\nSTAC_TRAIN_MAPPING_PATH = \"\"\nSTAC_CLASS_DICT_PATH = \"\"","id":"fa966f1c-ee96-4c2b-a07d-facccdcd65b8","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 追加公开数据集split的路径到配置文件\n!echo 'STAC_TRAIN_PATH = '\\\"{TRAIN_PATH}\\\" >> {PACKAGE_PATH}/config.py\n!echo 'STAC_VALID_PATH = '\\\"{VALID_PATH}\\\" >> {PACKAGE_PATH}/config.py","id":"88f80dd7-23bc-4cdf-a5f5-1b1fe59fd779","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 下载数据集\n本教程以公开数据集为例，展示如何加载远程数据集到 *Notebook* 环境","id":"74d2b83d-ed78-4df8-b299-5a13724b2ae8","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 下载数据集需要等待一段时间，具体视数据集大小而定\n\nimport os\nfrom cnn_clf_demo import config\nsource_train_path = config.STAC_TRAIN_PATH.replace(\"oss://\" + config.OPEN_DATA_BUCKET, \"\").strip(\"/\")\ntarget_train_path = os.path.join(PACKAGE_PATH, \"data\", source_train_path)\n\nsource_valid_path = config.STAC_VALID_PATH.replace(\"oss://\" + config.OPEN_DATA_BUCKET, \"\").strip(\"/\")\ntarget_valid_path = os.path.join(PACKAGE_PATH, \"data\", source_valid_path)\n\ndata_abs_path = os.path.join(os.getcwd(), target_train_path)\nos.makedirs(os.path.dirname(data_abs_path), exist_ok=True)\n\nMlProxy.get_oss_object(source_train_path, target_train_path, oss_root_dir=\"./\", oss_bucket_name=config.OPEN_DATA_BUCKET, oss_endpoint=config.OPEN_DATA_ENDPOINT)\nMlProxy.get_oss_object(source_valid_path, target_valid_path, oss_root_dir=\"./\", oss_bucket_name=config.OPEN_DATA_BUCKET, oss_endpoint=config.OPEN_DATA_ENDPOINT)\n","id":"50b9ca30-d915-4d3c-b721-024931da2cbe","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 模型开发","id":"0d5ea755-98ed-4fbd-b4ce-cf016c91c911","cell_type":"markdown"},{"metadata":{},"execution_count":null,"source":"#### datasets相关功能接口","id":"f92a00ae-67ce-4d78-ab91-361bc6323e06","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"%%writefile {PACKAGE_PATH}/datasets.py\n\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torch\nimport tarfile\nimport oss2\nimport os\nimport json\n\n\ndef remove_invalid_file(data_dir):\n    for root, dirs, files in os.walk(data_dir, topdown=False):\n        for fname in files:\n            fpath = os.path.join(root, fname)\n            if fname.startswith(\".\"):\n                os.remove(fpath)\n    print(\"** Remove invalid data finished .\")\n\n\ndef load_tmp_cred_info(cred_file_path):\n    res = {}\n    with open(cred_file_path, \"r\") as f:\n        res = json.loads(f.readlines()[0])\n    return res\n\ndef download_oss_object(ak, akSec, security_token, host, bucket_name, source_object_path, target_object_path):\n    \"\"\"\n    Download oss file/gzip to local dir.\n    \"\"\"\n    auth = oss2.StsAuth(ak, akSec, security_token)\n    bucket = oss2.Bucket(auth, host, bucket_name)\n    bucket.get_object_to_file(source_object_path, target_object_path)\n    \n    print(\"** Download finished !\")\n    \n\ndef upload_object_to_oss(ak, akSec, security_token, host, bucket_name, oss_filename, local_filename):\n    \"\"\"\n    Desc:\n        Put a local object to OSS.\n    Args:\n        oss_filename <string>: The oss filename. Example: pai/cnn_clf_demo/cnn_clf_demo.tar.gz\n        local_filename <string>: The local filename. Example: ./cnn_clf_demo.tar.gz\n    \"\"\"\n    auth = oss2.StsAuth(ak, akSec, security_token)\n    bucket = oss2.Bucket(auth, host, bucket_name)\n    bucket.put_object_from_file(oss_filename, local_filename)\n    \n    print(\"** Upload finished !\")\n    \n\ndef untar(fname, dirs):\n    \"\"\"\n    解压tar.gz文件\n    :param fname: 压缩文件名\n    :param dirs: 解压后的存放路径\n    :return: bool\n    \"\"\"\n    try:\n        with tarfile.open(fname, \"r:gz\") as fp:\n            fp.extractall(path=dirs)\n        return True\n    except Exception as e:\n        print(e)\n        return False\n\n    \ndef make_targz(output_filename, source_dir):\n    \"\"\"\n    一次性打包目录为tar.gz\n    :param output_filename: 压缩文件名\n    :param source_dir: 需要打包的目录\n    :return: bool\n    \"\"\"\n    try:\n        with tarfile.open(output_filename, \"w:gz\") as tar:\n            tar.add(source_dir, arcname=os.path.basename(source_dir))\n\n        return True\n    except Exception as e:\n        print(e)\n        return False\n    \n\ndef get_data_loader(data_dir, transforms, batch_size, shuffle=True, num_workers=0):\n    # Get dataset obj\n    dataset = datasets.ImageFolder(\n        data_dir,\n        transforms\n    )\n    # Get torch dataLoader obj\n    data_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers\n    )\n    \n    return data_loader\n    \n\ndef get_transforms():\n    transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    return transformations","id":"9222bdfe-b60a-403c-9583-9d700c201dd7","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 模型网络定义","id":"62dac688-aa08-47cf-a22e-30c4e6b340be","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"%%writefile {PACKAGE_PATH}/model.py\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\n\n\n# Define a CNN Net\nclass CnnDemoNet(nn.Module):\n    def __init__(self):\n        super(CnnDemoNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(12)\n        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(12)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(24)\n        self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(24)\n        \n        self.fc1 = nn.Linear(24*10*10, 10)\n        \n    \n    def forward(self, input):\n        output = F.relu(self.bn1(self.conv1(input)))\n        output = F.relu(self.bn2(self.conv2(output)))\n        output = self.pool(output)\n        output = F.relu(self.bn3(self.conv3(output)))\n        output = F.relu(self.bn4(self.conv4(output)))\n        output = output.view(-1, 24*10*10)\n        output = self.fc1(output)\n        \n        return output","id":"e5ab2e61-a10e-4aae-9578-495e3eef9031","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 训练过程","id":"c1b21564-98d1-4b9c-b9a8-0e824c06645c","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"%%writefile {PACKAGE_PATH}/train.py\n\nimport os\nimport shutil\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nimport config\nfrom datasets import *\nfrom model import CnnDemoNet\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--inputs\", type=str, default='Inputs dir')\nparser.add_argument(\"--checkpointDir\", type=str, default='Checkpoint dir')\n\nargs = parser.parse_args()\nprint(\"** InputsDir:\", args.inputs)\nprint(\"** CheckpointDir:\", args.checkpointDir)\n\ntmp_cred_dict = load_tmp_cred_info(\".tmp_info\")\n\n\nimport torch\nprint(\"** torch version:\", torch.__version__)\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"** The model will be running on\", DEVICE, \"device\")\n\n# create local tmp dir\nos.makedirs(config.PAI_LOCAL_TMP_DIR, exist_ok=True)\n\n\ndef save_model(model, model_path):\n    torch.save(model.state_dict(), model_path)\n    \n    \n## Test ACC\ndef test_acc(model, valid_loader, device):\n    model.eval()\n    acc = 0.0\n    total = 0.0\n    \n    with torch.no_grad():\n        for data in valid_loader:\n            images,labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _,predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            acc += (predicted == labels).sum().item()\n            \n    acc = (acc / total)\n    return (acc)\n    \n\ndef data_process():\n    \n    train_set_name = os.path.basename(config.STAC_TRAIN_PATH)\n    valid_set_name = os.path.basename(config.STAC_VALID_PATH)\n    \n    # untar gzip packages\n    untar(\"./data/cifar-10/\" + train_set_name, \"./data\")\n    untar(\"./data/cifar-10/\" + valid_set_name, \"./data\")\n    \n    # remove invalid data\n    remove_invalid_file(\"./data\")\n    \n    # get DataLoader\n    transformations = get_transforms()\n    train_loader = get_data_loader(os.path.join(\"./data\", train_set_name.split(\".\")[0]), transformations, config.BATCH_SIZE, shuffle=True, num_workers=0)\n    valid_loader = get_data_loader(os.path.join(\"./data\", valid_set_name.split(\".\")[0]), transformations, config.BATCH_SIZE, shuffle=False, num_workers=0)\n    \n    return train_loader, valid_loader\n\n    \n# Training model\ndef train():\n\n    # Model instance\n    model = CnnDemoNet()  \n\n    # Dataloaders\n    train_loader, valid_loader = data_process()\n    print(\"** Train len: \", len(train_loader))\n    print(\"** Valid len: \", len(valid_loader))\n    \n    # Loss and Optimizer\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n\n    \n    # Training process\n    best_acc = 0.0\n    model.to(DEVICE)\n    for epoch in range(config.NUM_EPOCHES):\n        running_loss = 0.0\n        running_acc = 0.0\n        for i, (images,labels) in enumerate(train_loader, 0):\n            images = Variable(images.to(DEVICE))\n            labels = Variable(labels.to(DEVICE))\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if i % 50 == 49:\n                print(\"[%d, %5d] loss: %.4f\" % (epoch+1, i+1, running_loss/50))\n            running_loss = 0.0\n\n            # validation \n            acc = test_acc(model, valid_loader, DEVICE)\n            print(\"For epoch\", epoch+1, \"the acc on validation set is %.4f\" % (acc))\n\n            if acc > best_acc:\n                # 暂存到临时文件夹\n                save_model(model, os.path.join(config.PAI_LOCAL_TMP_DIR, config.OUTPUT_MODEL_FILE_NAME)) \n                best_acc = acc\n\n    # 将tmp目录中的 bestModel pth文件 传到OSS的checkpoint路径中  TMP_ACCESS_ID, TMP_ACCESS_SEC, config.OSS_HOST, TMP_BUCKET_NAME\n    upload_object_to_oss(tmp_cred_dict.get('ossStsAccessKeyId'), \n                         tmp_cred_dict.get('ossStsAccessKeySecret'), \n                         tmp_cred_dict.get('ossStsAccessSecurityToken'), \n                         config.OSS_HOST, \n                         tmp_cred_dict.get('ossBucketName'), \n                         os.path.join(tmp_cred_dict.get('userWorkDir'), config.OSS_CHECKPOINT_DIR, config.OUTPUT_MODEL_FILE_NAME), \n                         os.path.join(config.PAI_LOCAL_TMP_DIR, config.OUTPUT_MODEL_FILE_NAME))\n\n    # 清理临时文件夹\n    shutil.rmtree(config.PAI_LOCAL_TMP_DIR)\n\n    print(\"** Training process done .\\n\")\n    \n\nif __name__ == \"__main__\":\n    print(\"** Start training process.\\n\")\n    \n    train()","id":"5dced50f-83e8-410d-8d23-4a1fffe8b624","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 代码打包上传\n* 获取临时授权\n* 代码打包\n* 代码包上传到远端存储","id":"ffb45609-7553-4065-ae15-40346a8dbe16","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 获取临时授权信息，并添加到代码包中\nMlProxy.save_tmp_cred(PACKAGE_PATH)\n\n# 代码打包，建议使用tar.gz格式\n!cd {PACKAGE_PATH} && tar -zcvf {PACKAGE_PATH}.tar.gz --exclude=__pycache__ ./* .[!.]*  &&  mv {PACKAGE_PATH}.tar.gz ../","id":"17583835-081d-40ae-a543-69637a7b7586","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 将代码包上传到云端\n\nimport os\nfrom cnn_clf_demo import config\n\nscript_object_name = os.path.join(config.OSS_WORK_DIR, PACKAGE_PATH+\".tar.gz\")\nlocal_filename = os.path.join(PACKAGE_PATH+\".tar.gz\")\nprint(\"** object_name:\", script_object_name)\nprint(\"** local_filename:\", local_filename)\n\nMlProxy.put_oss_object(script_object_name, local_filename)","id":"bddc9c99-c7d6-4ed5-8ddb-815f00b97414","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 提交训练任务\n* 组装训练参数 *data*\n* 使用 *MlProxy.commit_model_job()* 函数提交任务到训练集群\n* 提交任务后，返回任务 *logview* 链接，查看训练进度、打印输出和错误信息","id":"571e4555-fca0-41d0-9766-deeb20037ae1","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 提交训练任务\n\nimport imp\nimport os\n\nimport cnn_clf_demo\nfrom cnn_clf_demo import config\nimp.reload(cnn_clf_demo.config)\n\n# 装配任务参数\ndata = {'script': script_object_name, 'entryFile': 'train.py', 'checkpointDir': config.OSS_CHECKPOINT_DIR}\n\n# 任务提交，返回带有jobId和jobLogview等信息的字典\nret = MlProxy.commit_model_job(data)\njob_id = ret['jobId']\nprint(job_id)","id":"77791058-b5c8-4170-b836-0dea0108b7cc","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 查看任务状态","id":"b6146eb9-4bf3-4d61-8e66-36bd3257c202","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 获取任务状态\nMlProxy.get_job_status(job_id)","id":"104ada05-4bd2-4427-ac25-a14e7fa1755e","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 查看任务日志","id":"9103eeb0-3cec-48c4-a29f-9bdb046b2ff5","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"print(ret['jobLogview'])","id":"34a4645b-e0bf-4580-908b-ae1d08d82d24","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 停止任务","id":"f4670bc4-cac9-4036-916a-e36aa4f9f382","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"MlProxy.stop_job(job_id)","id":"61864286-0b9c-43f8-9240-59e6efbb5b07","cell_type":"code"},{"metadata":{"tags":[]},"execution_count":null,"source":"### 模型评估","id":"964154ca-1d1b-45d3-96e2-610420a0a97d","cell_type":"markdown"},{"metadata":{},"execution_count":null,"source":"#### 评估主流程代码","id":"4d0c872a-0a5d-4074-b54f-aaef79c1786f","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"%%writefile {PACKAGE_PATH}/evaluation.py\n\nimport os\nimport shutil\nfrom torch.autograd import Variable\nimport config\nfrom datasets import *\nfrom model import CnnDemoNet\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--inputs\", type=str, default='Inputs dir')\nparser.add_argument(\"--checkpointDir\", type=str, default='Checkpoint dir')\n\nargs = parser.parse_args()\nprint(\"** InputsDir:\", args.inputs)\nprint(\"** CheckpointDir:\", args.checkpointDir)\n\n\nimport torch\nprint(\"** torch version:\", torch.__version__)\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"** The model will be running on\", DEVICE, \"device\")\n\n# create local temp dir\nos.makedirs(config.PAI_LOCAL_TMP_DIR, exist_ok=True)\n\n# 由于在训练集群中需要与云端数据存储进行通信，所以需要获取临时授权信息\ndef load_model_file():\n    # get temp sts credentials\n    tmp_cred_dict = load_tmp_cred_info(\".tmp_info\")\n    \n    model_object_key = os.path.join(tmp_cred_dict.get('userWorkDir'), config.OSS_CHECKPOINT_DIR, config.OUTPUT_MODEL_FILE_NAME)\n    local_model_path = os.path.join(config.PAI_LOCAL_TMP_DIR, config.OUTPUT_MODEL_FILE_NAME)\n    \n    download_oss_object(tmp_cred_dict.get('ossStsAccessKeyId'), \n                         tmp_cred_dict.get('ossStsAccessKeySecret'), \n                         tmp_cred_dict.get('ossStsAccessSecurityToken'), \n                         config.OSS_HOST, \n                         tmp_cred_dict.get('ossBucketName'), \n                         model_object_key, \n                         local_model_path)\n    \n    print(\"*** Load model file finished !\")\n    return local_model_path\n    \n    \n## Test ACC\ndef test_acc(model, valid_loader, device):\n    model.eval()\n    acc = 0.0\n    total = 0.0\n    model.to(device)\n    with torch.no_grad():\n        for data in valid_loader:\n            images,labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _,predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            acc += (predicted == labels).sum().item()\n            \n    acc = (acc / total)\n    return (acc)\n\n\ndef imageshow(img):\n    img = img/2 + 0.5\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    \n\ndef testBatch(test_loader):\n    images,labels = next(iter(test_loader))\n    imageshow(torchvision.utils.make_grid(images))\n    print(\"\")\n    \n\ndef data_process():\n    \n    valid_set_name = os.path.basename(config.STAC_VALID_PATH)\n    \n    # untar gzip packages\n    untar(\"./data/cifar-10/\" + valid_set_name, \"./data\")\n    \n    # remove invalid data\n    remove_invalid_file(\"./data\")\n    \n    # get DataLoader\n    transformations = get_transforms()\n    valid_loader = get_data_loader(os.path.join(\"./data\", valid_set_name.split(\".\")[0]), transformations, config.BATCH_SIZE, shuffle=False, num_workers=0)\n    return valid_loader\n\n\n    \n# Test model\ndef test(model_path):\n\n    # Model instance\n    model = CnnDemoNet()  \n\n    # Dataloaders\n    valid_loader = data_process()\n    print(\"** Valid len: \", len(valid_loader))\n    \n    # load model\n    model.load_state_dict(torch.load(model_path))\n\n    acc = test_acc(model, valid_loader, DEVICE)\n    print(\"--the evaluation ACC on valid_set is %.4f\" % (acc))\n    \n    # 清理临时文件夹\n    shutil.rmtree(config.PAI_LOCAL_TMP_DIR)\n\n    print(\"** Test process done .\\n\")\n    \n\nif __name__ == \"__main__\":\n    print(\"** Start Test process.\\n\")\n    \n    model_path = load_model_file()\n    test(model_path)\n","id":"a3bfe0c3-cc50-47b9-a267-ec7567eb555d","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 评估代码打包和上传\n* 临时授权文件加载和保存\n* 代码打包\n* 代码包上传到远端存储","id":"a418f6c2-f671-4144-b768-89d3bd120d81","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 存储临时授权信息\nMlProxy.save_tmp_cred(PACKAGE_PATH)\n\n# 评估代码打包，建议使用tar.gz格式\n!cd {PACKAGE_PATH} && tar -zcvf {PACKAGE_PATH}.tar.gz --exclude=__pycache__ --exclude=./data/cifar-10/train.tar.gz ./* .[!.]*  &&  mv {PACKAGE_PATH}.tar.gz ../","id":"b01b6e49-888e-4819-93e5-c01d818cfe5d","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 代码包上传到云端\n\nimport os\nfrom cnn_clf_demo import config\n\nscript_object_name = os.path.join(config.OSS_WORK_DIR, PACKAGE_PATH+\".tar.gz\")\nlocal_filename = os.path.join(PACKAGE_PATH+\".tar.gz\")\nprint(\"** object_name:\", script_object_name)\nprint(\"** local_filename:\", local_filename)\n\nMlProxy.put_oss_object(script_object_name, local_filename)","id":"b8475761-570f-48fb-8ba8-9616b09729c8","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 评估任务提交\n* 组装任务参数 *data*\n* 使用 *MlProxy.commit_model_job()* 函数提交任务到集群\n* 提交任务后，返回任务 *logview* 链接，查看评估进度、打印输出和错误信息","id":"a4299532-d6bc-45e4-9c00-9f0ef8994581","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"# 提交评估任务\n\nimport imp\nimport os\n\nimport cnn_clf_demo\nfrom cnn_clf_demo import config\nimp.reload(cnn_clf_demo.config)\n\n# 组装任务参数\ndata = {'script': script_object_name, 'entryFile': 'evaluation.py', 'checkpointDir': config.OSS_CHECKPOINT_DIR}\n\n# 提交任务，返回jobId和jobLogview等信息的字典\nret = MlProxy.commit_model_job(data)\njob_id = ret['jobId']\nprint(job_id)","id":"9b010c78-e154-4779-bb3a-3a4cc396e0ea","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"### 查看评估任务状态","id":"b3517032-2562-4cf9-8688-98e19ffbfe5c","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"MlProxy.get_job_status(job_id)","id":"4ce26e46-6d47-4272-a05c-1b72031a5dd8","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 查看任务日志","id":"c882341f-7291-444f-b218-c348d5dec790","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"print(ret['jobLogview'])","id":"277ad69e-6adf-4246-90bb-3fec92411820","cell_type":"code"},{"metadata":{},"execution_count":null,"source":"#### 停止评估任务","id":"a5722ec5-734b-4625-8b44-6d9e72528f84","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"MlProxy.stop_job(job_id)","id":"b408102d-8468-4e90-a423-6667f6ebf414","cell_type":"code"}],"nbformat":4}